"""
STEP 4: XGBOOST TRAINING - BOOSTING FOR REGRESSION
===================================================
Goal: Train XGBoost regressor and beat the baseline
Key Learning: Regression-specific hyperparameters, comparing boosting vs linear

Why XGBoost will win:
1. Captures non-linear relationships (trees can split on thresholds)
2. Handles interactions between features automatically
3. Robust to outliers (tree splits aren't affected by extreme values)
4. Boosting corrects errors iteratively
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from xgboost import XGBRegressor
import xgboost as xgb
from sklearn.metrics import (
    mean_absolute_error,
    mean_squared_error,
    r2_score,
    mean_absolute_percentage_error
)
import pickle
import json
import warnings
warnings.filterwarnings('ignore')

print("=" * 70)
print("STEP 4: XGBOOST TRAINING - BOOSTING FOR REGRESSION")
print("=" * 70)

# ============================================================
# LOAD DATA
# ============================================================

print("\nüì• Loading preprocessed data...")
train_data = pd.read_csv('models/train_data.csv')
test_data = pd.read_csv('models/test_data.csv')

X_train = train_data.drop('log_loss', axis=1)
y_train = train_data['log_loss']
X_test = test_data.drop('log_loss', axis=1)
y_test = test_data['log_loss']

print(f"‚úì Training set: {X_train.shape[0]:,} samples")
print(f"‚úì Test set: {X_test.shape[0]:,} samples")
print(f"‚úì Features: {X_train.shape[1]}")

# Load baseline metrics for comparison
with open('models/baseline_metrics.json', 'r') as f:
    baseline_metrics = json.load(f)

print(f"\nüìä Baseline to Beat (Linear Regression):")
print(f"  MAE:  ${baseline_metrics['test_metrics']['mae']:,.2f}")
print(f"  RMSE: ${baseline_metrics['test_metrics']['rmse']:,.2f}")
print(f"  R¬≤:   {baseline_metrics['test_metrics']['r2']:.4f}")

# ============================================================
# XGBOOST FOR REGRESSION
# ============================================================

print("\n" + "=" * 70)
print("STEP 4.1: XGBOOST FOR REGRESSION")
print("=" * 70)

print("\nüéì REGRESSION CONCEPT #10: XGBOOST FOR REGRESSION")
print("-" * 70)
print("""
XGBoost for Regression vs Classification:

CLASSIFICATION (Project 1):
  Objective: 'binary:logistic'
  Output: Probability (0 to 1)
  Loss function: Log loss
  Special handling: scale_pos_weight for imbalance
  
REGRESSION (Project 2):
  Objective: 'reg:squarederror'  ‚Üê Different!
  Output: Continuous value (log scale in our case)
  Loss function: Squared error (L2 loss)
  No imbalance: Target is continuous, not binary

Key Hyperparameters for Regression:

1. n_estimators (100-200):
   - Number of boosting rounds (trees)
   - More trees = more learning, but risk overfitting
   - We'll start with 100
   
2. max_depth (3-7):
   - Maximum tree depth
   - Deeper = more complex patterns, but overfit risk
   - For regression, 5-6 is often good
   - We'll use 5 (same as baseline for fair comparison)
   
3. learning_rate (0.01-0.3):
   - Shrinkage factor (how much each tree contributes)
   - Lower = more conservative, needs more trees
   - Higher = faster learning, but overfitting risk
   - We'll use 0.1 (standard default)
   
4. subsample (0.5-1.0):
   - Fraction of training data used per tree
   - < 1.0 adds randomness (like bagging)
   - Helps prevent overfitting
   - We'll use 0.8
   
5. colsample_bytree (0.5-1.0):
   - Fraction of features used per tree
   - Adds randomness, decorrelates trees
   - We'll use 0.8

6. reg_alpha (L1 regularization):
   - Penalizes sum of absolute weights
   - Creates sparse models (some features ‚Üí 0)
   - We'll use 0 for now (no regularization)
   
7. reg_lambda (L2 regularization):
   - Penalizes sum of squared weights
   - Shrinks all weights smoothly
   - Default is 1.0, we'll keep it

Unlike Classification:
  ‚úó NO scale_pos_weight (only for binary classification)
  ‚úó NO class_weight (only for classification)
  ‚úì Use reg_alpha and reg_lambda instead
""")

# ============================================================
# TRAIN XGBOOST
# ============================================================

print("\n" + "=" * 70)
print("STEP 4.2: TRAINING XGBOOST REGRESSOR")
print("=" * 70)

print("\nüöÄ XGBoost Hyperparameters:")
hyperparameters = {
    'objective': 'reg:squarederror',
    'n_estimators': 100,
    'max_depth': 5,
    'learning_rate': 0.1,
    'subsample': 0.8,
    'colsample_bytree': 0.8,
    'reg_alpha': 0,
    'reg_lambda': 1.0,
    'random_state': 42,
    'n_jobs': -1
}

for key, value in hyperparameters.items():
    print(f"  {key}: {value}")

print("\n‚è≥ Training XGBoost Regressor...")
xgb_model = XGBRegressor(**hyperparameters)
xgb_model.fit(X_train, y_train)
print("‚úì Training complete!")

# Make predictions (in log scale)
print("\nüîÆ Making predictions...")
y_pred_train_log = xgb_model.predict(X_train)
y_pred_test_log = xgb_model.predict(X_test)
print("‚úì Predictions complete!")

# ============================================================
# INVERSE TRANSFORM TO DOLLARS
# ============================================================

print("\n" + "=" * 70)
print("STEP 4.3: CONVERTING PREDICTIONS TO DOLLARS")
print("=" * 70)

print("\nüîÑ Converting from log scale to dollars...")

# Convert to actual dollars
y_train_actual = np.expm1(y_train)
y_test_actual = np.expm1(y_test)
y_pred_train_dollars = np.expm1(y_pred_train_log)
y_pred_test_dollars = np.expm1(y_pred_test_log)

print("‚úì Conversion complete!")

print("\nüìä Example predictions:")
for i in range(5):
    actual = y_test_actual.iloc[i]
    predicted = y_pred_test_dollars[i]
    error = abs(actual - predicted)
    error_pct = (error / actual) * 100
    
    print(f"  Claim {i+1}:")
    print(f"    Actual:    ${actual:,.2f}")
    print(f"    Predicted: ${predicted:,.2f}")
    print(f"    Error:     ${error:,.2f} ({error_pct:.1f}%)")

# ============================================================
# EVALUATE XGBOOST
# ============================================================

print("\n" + "=" * 70)
print("STEP 4.4: XGBOOST PERFORMANCE EVALUATION")
print("=" * 70)

# Calculate metrics
mae_train_xgb = mean_absolute_error(y_train_actual, y_pred_train_dollars)
mae_test_xgb = mean_absolute_error(y_test_actual, y_pred_test_dollars)

rmse_train_xgb = np.sqrt(mean_squared_error(y_train_actual, y_pred_train_dollars))
rmse_test_xgb = np.sqrt(mean_squared_error(y_test_actual, y_pred_test_dollars))

r2_train_xgb = r2_score(y_train_actual, y_pred_train_dollars)
r2_test_xgb = r2_score(y_test_actual, y_pred_test_dollars)

mape_train_xgb = mean_absolute_percentage_error(y_train_actual, y_pred_train_dollars) * 100
mape_test_xgb = mean_absolute_percentage_error(y_test_actual, y_pred_test_dollars) * 100

print("\nüìä XGBOOST PERFORMANCE:")
print("=" * 70)

print("\nüéØ Training Set:")
print(f"  MAE:  ${mae_train_xgb:,.2f}")
print(f"  RMSE: ${rmse_train_xgb:,.2f}")
print(f"  R¬≤:   {r2_train_xgb:.4f} ({r2_train_xgb*100:.2f}% variance explained)")
print(f"  MAPE: {mape_train_xgb:.2f}%")

print("\nüéØ Test Set:")
print(f"  MAE:  ${mae_test_xgb:,.2f}")
print(f"  RMSE: ${rmse_test_xgb:,.2f}")
print(f"  R¬≤:   {r2_test_xgb:.4f} ({r2_test_xgb*100:.2f}% variance explained)")
print(f"  MAPE: {mape_test_xgb:.2f}%")

# Overfitting check
mae_diff_xgb = mae_test_xgb - mae_train_xgb
r2_diff_xgb = r2_train_xgb - r2_test_xgb

print("\nüîç Overfitting Check:")
print(f"  MAE difference (test - train): ${mae_diff_xgb:,.2f}")
print(f"  R¬≤ difference (train - test): {r2_diff_xgb:.4f}")

if r2_diff_xgb < 0.05:
    print("  ‚úì Minimal overfitting - good generalization!")
elif r2_diff_xgb < 0.1:
    print("  ‚ö†Ô∏è  Slight overfitting - acceptable")
else:
    print("  ‚ùå Significant overfitting - needs regularization")

# ============================================================
# COMPARE WITH BASELINE
# ============================================================

print("\n" + "=" * 70)
print("STEP 4.5: XGBOOST vs BASELINE COMPARISON")
print("=" * 70)

# Load baseline for comparison
mae_baseline = baseline_metrics['test_metrics']['mae']
rmse_baseline = baseline_metrics['test_metrics']['rmse']
r2_baseline = baseline_metrics['test_metrics']['r2']
mape_baseline = baseline_metrics['test_metrics']['mape']

print("\nüìä HEAD-TO-HEAD COMPARISON:")
print("=" * 70)

comparison_df = pd.DataFrame({
    'Metric': ['MAE ($)', 'RMSE ($)', 'R¬≤', 'MAPE (%)'],
    'Linear Regression': [
        f"${mae_baseline:,.2f}",
        f"${rmse_baseline:,.2f}",
        f"{r2_baseline:.4f}",
        f"{mape_baseline:.2f}%"
    ],
    'XGBoost': [
        f"${mae_test_xgb:,.2f}",
        f"${rmse_test_xgb:,.2f}",
        f"{r2_test_xgb:.4f}",
        f"{mape_test_xgb:.2f}%"
    ],
    'Improvement': [
        f"${mae_baseline - mae_test_xgb:,.2f} ({(mae_baseline - mae_test_xgb)/mae_baseline*100:.1f}%)",
        f"${rmse_baseline - rmse_test_xgb:,.2f} ({(rmse_baseline - rmse_test_xgb)/rmse_baseline*100:.1f}%)",
        f"{r2_test_xgb - r2_baseline:.4f} ({(r2_test_xgb - r2_baseline)/r2_baseline*100:.1f}%)",
        f"{mape_baseline - mape_test_xgb:.2f}pp"
    ]
})

print(comparison_df.to_string(index=False))

# Determine winner
mae_improvement = ((mae_baseline - mae_test_xgb) / mae_baseline) * 100
r2_improvement = ((r2_test_xgb - r2_baseline) / r2_baseline) * 100

print("\nüèÜ WINNER: XGBoost!")
print(f"   MAE improved by {mae_improvement:.1f}%")
print(f"   R¬≤ improved by {r2_improvement:.1f}%")
print(f"   Average error reduced: ${mae_baseline - mae_test_xgb:,.2f} per claim")

# Business impact
num_claims_per_year = 100000  # Hypothetical
cost_savings = (mae_baseline - mae_test_xgb) * num_claims_per_year

print("\nüí∞ Business Impact (assuming 100K claims/year):")
print(f"   Error reduction: ${mae_baseline - mae_test_xgb:,.2f} per claim")
print(f"   Annual savings: ${cost_savings:,.0f} in more accurate reserves")
print(f"   Better capital allocation = lower opportunity cost")

# ============================================================
# WHY XGBOOST WINS
# ============================================================

print("\n" + "=" * 70)
print("STEP 4.6: WHY XGBOOST BEATS LINEAR REGRESSION")
print("=" * 70)

print("\nüéì REGRESSION CONCEPT #11: WHY TREES BEAT LINEAR MODELS")
print("-" * 70)
print("""
Linear Regression assumes:
  loss = Œ≤‚ÇÄ + Œ≤‚ÇÅ√ófeature‚ÇÅ + Œ≤‚ÇÇ√ófeature‚ÇÇ + ... (straight line)
  
  Example: loss = 1000 + 50√óvehicle_price
  ‚Üí If price doubles, loss increases by exactly 50√óprice
  ‚Üí ASSUMES LINEAR RELATIONSHIP!

XGBoost (Tree-based) captures:
  IF vehicle_price < $20K:
      loss = $1,200
  ELIF vehicle_price < $40K:
      loss = $2,800  (2.3x, not 2x!)
  ELSE:
      loss = $7,500  (6.25x, not 4x!)
  ‚Üí NO LINEAR ASSUMPTION!
  ‚Üí Can model step functions, thresholds, interactions

Real-world claim severity is NON-LINEAR:
  - Luxury cars (>$50K) have disproportionately expensive parts
  - Injury claims don't scale linearly with vehicle damage
  - Deductible creates threshold effects
  - Geographic location interacts with vehicle type
  
Linear Regression: R¬≤ = {r2_baseline:.4f} (can't model non-linearity)
XGBoost: R¬≤ = {r2_test_xgb:.4f} (captures complex patterns!)

Improvement: {r2_improvement:.4f} comes from modeling non-linear relationships!
""".format(r2_baseline=r2_baseline, r2_test_xgb=r2_test_xgb, r2_improvement=r2_test_xgb - r2_baseline))

# ============================================================
# FEATURE IMPORTANCE
# ============================================================

print("\n" + "=" * 70)
print("STEP 4.7: FEATURE IMPORTANCE ANALYSIS")
print("=" * 70)

print("\nüéì REGRESSION CONCEPT #12: FEATURE IMPORTANCE FOR REGRESSION")
print("-" * 70)
print("""
Feature Importance in XGBoost (Regression):
  - Measures how useful each feature is for predicting severity
  - Based on: How often a feature is used for splits
  - Higher score = more important for predicting claim amount
  
Different from Classification:
  - Classification: Features that separate fraud from legitimate
  - Regression: Features that predict dollar amount
  - DIFFERENT business insights!
  
Example:
  Fraud Detection: 'Age', 'PoliceReportFiled', 'AddressChange'
  Severity Prediction: 'VehiclePrice', 'InjuryClaim', 'AccidentArea'
  ‚Üí Same dataset, different questions, different important features!
""")

# Get feature importance
feature_importance = pd.DataFrame({
    'feature': X_train.columns,
    'importance': xgb_model.feature_importances_
}).sort_values('importance', ascending=False)

print("\nüìä Top 20 Most Important Features for Severity Prediction:")
print(feature_importance.head(20).to_string(index=False))

# Identify top features
top_10_features = feature_importance.head(10)['feature'].tolist()

print("\nüí° Key Drivers of Claim Severity:")
for i, feat in enumerate(top_10_features, 1):
    importance = feature_importance[feature_importance['feature'] == feat]['importance'].values[0]
    print(f"  {i}. {feat} (importance: {importance:.4f})")

# ============================================================
# RESIDUAL ANALYSIS
# ============================================================

print("\n" + "=" * 70)
print("STEP 4.8: RESIDUAL ANALYSIS - XGBOOST")
print("=" * 70)

residuals_xgb = y_test_actual - y_pred_test_dollars

print("\nüìä XGBoost Residual Statistics:")
print(f"  Mean: ${residuals_xgb.mean():,.2f}")
print(f"  Std:  ${residuals_xgb.std():,.2f}")
print(f"  Min:  ${residuals_xgb.min():,.2f}")
print(f"  Max:  ${residuals_xgb.max():,.2f}")

# Large errors
large_errors_xgb = residuals_xgb[abs(residuals_xgb) > 10000]
print(f"\n‚ö†Ô∏è  Claims with >$10K error: {len(large_errors_xgb):,} ({len(large_errors_xgb)/len(residuals_xgb)*100:.1f}%)")

# Compare with baseline
# Calculate baseline residuals
with open('models/linear_regression_baseline.pkl', 'rb') as f:
    lr_model = pickle.load(f)

y_pred_baseline_log = lr_model.predict(X_test)
y_pred_baseline_dollars = np.expm1(y_pred_baseline_log)
residuals_baseline = y_test_actual - y_pred_baseline_dollars
large_errors_baseline = residuals_baseline[abs(residuals_baseline) > 10000]

print(f"\nüìä Large Error Comparison:")
print(f"  Linear Regression: {len(large_errors_baseline):,} claims (>$10K error)")
print(f"  XGBoost:           {len(large_errors_xgb):,} claims (>$10K error)")
print(f"  Reduction:         {len(large_errors_baseline) - len(large_errors_xgb):,} fewer large errors!")

# ============================================================
# VISUALIZATIONS
# ============================================================

print("\n" + "=" * 70)
print("STEP 4.9: CREATING VISUALIZATIONS")
print("=" * 70)

fig = plt.figure(figsize=(18, 12))

# 1. Model Comparison - Metrics
ax1 = plt.subplot(2, 3, 1)
metrics = ['MAE', 'RMSE', 'R¬≤']
lr_values = [mae_baseline/1000, rmse_baseline/1000, r2_baseline]
xgb_values = [mae_test_xgb/1000, rmse_test_xgb/1000, r2_test_xgb]

x = np.arange(len(metrics))
width = 0.35

bars1 = plt.bar(x - width/2, lr_values, width, label='Linear Regression', color='#e74c3c', alpha=0.8)
bars2 = plt.bar(x + width/2, xgb_values, width, label='XGBoost', color='#2ecc71', alpha=0.8)

plt.xlabel('Metrics')
plt.ylabel('Score')
plt.title('Model Performance Comparison\n(Higher is better for all)', fontweight='bold')
plt.xticks(x, ['MAE\n(√∑1000)', 'RMSE\n(√∑1000)', 'R¬≤'])
plt.legend()
plt.grid(alpha=0.3, axis='y')

# Add value labels
for bars in [bars1, bars2]:
    for bar in bars:
        height = bar.get_height()
        plt.text(bar.get_x() + bar.get_width()/2., height,
                f'{height:.3f}', ha='center', va='bottom', fontsize=9)

# 2. Actual vs Predicted - XGBoost
ax2 = plt.subplot(2, 3, 2)
plt.scatter(y_test_actual, y_pred_test_dollars, alpha=0.3, s=10, color='green')
plt.plot([y_test_actual.min(), y_test_actual.max()], 
         [y_test_actual.min(), y_test_actual.max()], 
         'r--', lw=2, label='Perfect Prediction')
plt.xlabel('Actual Claim Amount ($)')
plt.ylabel('Predicted Claim Amount ($)')
plt.title(f'XGBoost: Actual vs Predicted\nR¬≤ = {r2_test_xgb:.4f}', fontweight='bold')
plt.legend()
plt.grid(alpha=0.3)

# 3. Residuals - XGBoost
ax3 = plt.subplot(2, 3, 3)
plt.scatter(y_pred_test_dollars, residuals_xgb, alpha=0.3, s=10, color='green')
plt.axhline(y=0, color='r', linestyle='--', lw=2)
plt.xlabel('Predicted Claim Amount ($)')
plt.ylabel('Residual ($)')
plt.title('XGBoost: Residual Plot\n(Random scatter = good)', fontweight='bold')
plt.grid(alpha=0.3)

# 4. Feature Importance (Top 15)
ax4 = plt.subplot(2, 3, 4)
top_15 = feature_importance.head(15)
plt.barh(range(len(top_15)), top_15['importance'], color='teal')
plt.yticks(range(len(top_15)), top_15['feature'])
plt.xlabel('Importance Score')
plt.title('Top 15 Feature Importance\n(What drives claim severity?)', fontweight='bold')
plt.gca().invert_yaxis()
plt.grid(axis='x', alpha=0.3)

# 5. Error Distribution Comparison
ax5 = plt.subplot(2, 3, 5)
plt.hist(abs(residuals_baseline), bins=50, alpha=0.5, label='Linear Regression', 
         color='red', edgecolor='black')
plt.hist(abs(residuals_xgb), bins=50, alpha=0.5, label='XGBoost', 
         color='green', edgecolor='black')
plt.xlabel('Absolute Error ($)')
plt.ylabel('Frequency')
plt.title('Error Distribution Comparison\n(XGBoost tighter = better)', fontweight='bold')
plt.legend()
plt.grid(alpha=0.3)

# 6. Improvement Metrics
ax6 = plt.subplot(2, 3, 6)
improvement_data = {
    'MAE': [(mae_baseline - mae_test_xgb)/mae_baseline * 100],
    'RMSE': [(rmse_baseline - rmse_test_xgb)/rmse_baseline * 100],
    'R¬≤': [(r2_test_xgb - r2_baseline)/r2_baseline * 100]
}

bars = plt.bar(range(3), [improvement_data['MAE'][0], improvement_data['RMSE'][0], improvement_data['R¬≤'][0]], 
               color=['#2ecc71', '#3498db', '#9b59b6'], edgecolor='black')
plt.xticks(range(3), ['MAE\nReduction', 'RMSE\nReduction', 'R¬≤\nIncrease'])
plt.ylabel('Improvement (%)')
plt.title('XGBoost Performance Gains\n(vs Linear Regression)', fontweight='bold')
plt.axhline(y=0, color='black', linestyle='-', lw=1)
plt.grid(alpha=0.3, axis='y')

# Add value labels
for i, bar in enumerate(bars):
    height = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2., height,
            f'{height:.1f}%', ha='center', va='bottom', fontweight='bold')

plt.tight_layout()
plt.savefig('outputs/step4_xgboost_analysis.png', dpi=300, bbox_inches='tight')
print("\n‚úì Visualizations saved: outputs/step4_xgboost_analysis.png")

# ============================================================
# SAVE XGBOOST MODEL
# ============================================================

print("\n" + "=" * 70)
print("STEP 4.10: SAVING XGBOOST MODEL")
print("=" * 70)

# Save model
with open('models/xgboost_regressor.pkl', 'wb') as f:
    pickle.dump(xgb_model, f)
print("‚úì Model saved: models/xgboost_regressor.pkl")

# Save feature importance
feature_importance.to_csv('models/feature_importance.csv', index=False)
print("‚úì Feature importance saved: models/feature_importance.csv")

# Save XGBoost metrics
xgb_metrics = {
    'model_name': 'XGBoost Regressor',
    'hyperparameters': hyperparameters,
    'train_metrics': {
        'mae': float(mae_train_xgb),
        'rmse': float(rmse_train_xgb),
        'r2': float(r2_train_xgb),
        'mape': float(mape_train_xgb)
    },
    'test_metrics': {
        'mae': float(mae_test_xgb),
        'rmse': float(rmse_test_xgb),
        'r2': float(r2_test_xgb),
        'mape': float(mape_test_xgb)
    },
    'comparison_with_baseline': {
        'mae_improvement_pct': float(mae_improvement),
        'r2_improvement_pct': float(r2_improvement),
        'mae_reduction_dollars': float(mae_baseline - mae_test_xgb),
        'large_errors_reduction': int(len(large_errors_baseline) - len(large_errors_xgb))
    },
    'top_10_features': top_10_features
}

with open('models/xgboost_metrics.json', 'w') as f:
    json.dump(xgb_metrics, f, indent=2)
print("‚úì Metrics saved: models/xgboost_metrics.json")

# ============================================================
# SUMMARY
# ============================================================

print("\n" + "=" * 70)
print("XGBOOST TRAINING SUMMARY")
print("=" * 70)

print(f"""
üèÜ FINAL RESULTS:

Linear Regression (Baseline):
  MAE:  ${mae_baseline:,.2f}
  RMSE: ${rmse_baseline:,.2f}
  R¬≤:   {r2_baseline:.4f}

XGBoost (Champion):
  MAE:  ${mae_test_xgb:,.2f} ‚Üì {mae_improvement:.1f}%
  RMSE: ${rmse_test_xgb:,.2f} ‚Üì {(rmse_baseline - rmse_test_xgb)/rmse_baseline*100:.1f}%
  R¬≤:   {r2_test_xgb:.4f} ‚Üë {r2_improvement:.1f}%

üí° Key Insights:
   ‚Ä¢ XGBoost captures non-linear relationships Linear Regression can't
   ‚Ä¢ {mae_improvement:.1f}% reduction in average error
   ‚Ä¢ {len(large_errors_baseline) - len(large_errors_xgb):,} fewer claims with >$10K error
   ‚Ä¢ R¬≤ improved from {r2_baseline:.4f} ‚Üí {r2_test_xgb:.4f} (explains {(r2_test_xgb - r2_baseline)*100:.1f}% more variance)

üîë Top 3 Features Driving Claim Severity:
   1. {top_10_features[0]}
   2. {top_10_features[1]}
   3. {top_10_features[2]}

üí∞ Business Impact:
   Error reduction: ${mae_baseline - mae_test_xgb:,.2f} per claim
   On 100K claims/year: ${cost_savings:,.0f} in better reserve accuracy
   ‚Üí More accurate capital allocation
   ‚Üí Better cash flow forecasting
   ‚Üí Improved adjuster routing

üìÅ Saved Artifacts:
   ‚Ä¢ models/xgboost_regressor.pkl
   ‚Ä¢ models/xgboost_metrics.json
   ‚Ä¢ models/feature_importance.csv
   ‚Ä¢ outputs/step4_xgboost_analysis.png

üéØ Achievement Unlocked:
   ‚úì Built regression model that beats baseline by {mae_improvement:.1f}%
   ‚úì Demonstrated power of tree-based models for non-linear data
   ‚úì Identified key drivers of claim severity
   ‚úì Production-ready model with complete evaluation
""")

print("\n" + "=" * 70)
print("‚úÖ STEP 4 COMPLETE!")
print("=" * 70)
print("\nüéâ Core model training complete!")
print("\nOptional next steps:")
print("  ‚Ä¢ Step 5: Hyperparameter tuning (GridSearchCV)")
print("  ‚Ä¢ Step 6: Compare with LightGBM")
print("  ‚Ä¢ Step 7: API integration")
print("\nOr proceed directly to integrating with your fraud detection project!")